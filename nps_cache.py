import sqlite3
import json
import hashlib
from datetime import datetime, timedelta
import os
from typing import Dict, List, Optional, Any
import threading

class NPSCache:
    """
    SQLite ë¡œì»¬ ìºì‹œ ì‹œìŠ¤í…œ
    - ë¡œì»¬ì—ì„œ ë¹ ë¥¸ ì¡°íšŒ
    - Supabase ì¡°íšŒ íšŸìˆ˜ ìµœì†Œí™”
    - SQLiteì™€ Supabase ë™ê¸°í™”
    """
    
    def __init__(self, db_path: str = "nps_cache.db"):
        self.db_path = db_path
        self.lock = threading.Lock()  # ë™ì‹œ ì ‘ê·¼ ë°©ì§€
        self.init_database()
    
    def init_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° í…Œì´ë¸” ìƒì„±"""
        with self.lock:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # API ìºì‹œ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS api_cache (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    request_hash TEXT UNIQUE NOT NULL,
                    api_type TEXT NOT NULL,
                    request_params TEXT NOT NULL,
                    response_data TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    expires_at TIMESTAMP,
                    last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    access_count INTEGER DEFAULT 1
                )
            """)
            
            # ì‚¬ì—…ì¥ ê¸°ë³¸ ì •ë³´ ìºì‹œ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS workplace_cache (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    seq TEXT UNIQUE NOT NULL,
                    wkpl_nm TEXT NOT NULL,
                    bzowr_rgst_no TEXT,
                    data_crt_ym TEXT,
                    wkpl_road_nm_dtl_addr TEXT,
                    jnngp_cnt INTEGER,
                    crrmm_ntc_amt INTEGER,
                    avg_monthly_salary REAL,
                    nw_acqzr_cnt INTEGER,
                    lss_jnngp_cnt INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    access_count INTEGER DEFAULT 1,
                    sync_status TEXT DEFAULT 'pending'  -- pending, synced, error
                )
            """)
            
            # ë™ê¸°í™” ë¡œê·¸ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS sync_log (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    table_name TEXT NOT NULL,
                    operation TEXT NOT NULL,  -- insert, update, delete
                    record_id TEXT NOT NULL,
                    data_before TEXT,
                    data_after TEXT,
                    sync_status TEXT DEFAULT 'pending',  -- pending, synced, error
                    error_message TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    synced_at TIMESTAMP
                )
            """)
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_api_cache_hash ON api_cache(request_hash)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_api_cache_expires ON api_cache(expires_at)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_workplace_seq ON workplace_cache(seq)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_workplace_name ON workplace_cache(wkpl_nm)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_sync_log_status ON sync_log(sync_status)")
            
            conn.commit()
            conn.close()
            print("âœ… SQLite ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def generate_request_hash(self, api_type: str, params: Dict) -> str:
        """API ìš”ì²­ íŒŒë¼ë¯¸í„°ë¡œë¶€í„° í•´ì‹œ ìƒì„±"""
        sorted_params = sorted(params.items())
        param_string = f"{api_type}:{json.dumps(sorted_params, sort_keys=True)}"
        return hashlib.sha256(param_string.encode()).hexdigest()
    
    def get_api_cache(self, api_type: str, params: Dict) -> Optional[Dict]:
        """API ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        with self.lock:
            request_hash = self.generate_request_hash(api_type, params)
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT response_data, expires_at FROM api_cache 
                WHERE request_hash = ? 
                AND (expires_at IS NULL OR expires_at > ?)
            """, (request_hash, datetime.now()))
            
            result = cursor.fetchone()
            
            if result:
                # ì ‘ê·¼ íšŸìˆ˜ ì¦ê°€ ë° ë§ˆì§€ë§‰ ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
                cursor.execute("""
                    UPDATE api_cache 
                    SET access_count = access_count + 1, 
                        last_accessed = CURRENT_TIMESTAMP
                    WHERE request_hash = ?
                """, (request_hash,))
                conn.commit()
                
                print(f"ğŸ“¦ SQLite ìºì‹œì—ì„œ API ë°ì´í„° ì¡°íšŒ: {api_type}")
                conn.close()
                return json.loads(result[0])
            
            conn.close()
            return None
    
    def set_api_cache(self, api_type: str, params: Dict, response_data: Dict, expires_hours: int = 24):
        """API ì‘ë‹µ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥"""
        with self.lock:
            request_hash = self.generate_request_hash(api_type, params)
            expires_at = datetime.now() + timedelta(hours=expires_hours)
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO api_cache 
                (request_hash, api_type, request_params, response_data, expires_at, last_accessed, access_count)
                VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP, 1)
            """, (
                request_hash, 
                api_type, 
                json.dumps(params), 
                json.dumps(response_data), 
                expires_at
            ))
            
            conn.commit()
            conn.close()
            print(f"ğŸ’¾ SQLite ìºì‹œì— API ë°ì´í„° ì €ì¥: {api_type}")
    
    def get_workplace_cache(self, wkpl_nm: str, bzowr_rgst_no: str = None) -> List[Dict]:
        """ì‚¬ì—…ì¥ ì •ë³´ ìºì‹œì—ì„œ ì¡°íšŒ"""
        with self.lock:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê²°ê³¼ ë°˜í™˜
            cursor = conn.cursor()
            
            if bzowr_rgst_no:
                cursor.execute("""
                    SELECT * FROM workplace_cache 
                    WHERE wkpl_nm = ? AND bzowr_rgst_no = ?
                """, (wkpl_nm, bzowr_rgst_no))
            else:
                cursor.execute("""
                    SELECT * FROM workplace_cache 
                    WHERE wkpl_nm = ?
                """, (wkpl_nm,))
            
            results = cursor.fetchall()
            
            if results:
                # ì ‘ê·¼ íšŸìˆ˜ ì¦ê°€ ë° ë§ˆì§€ë§‰ ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
                for result in results:
                    cursor.execute("""
                        UPDATE workplace_cache 
                        SET access_count = access_count + 1, 
                            last_accessed = CURRENT_TIMESTAMP
                        WHERE id = ?
                    """, (result['id'],))
                
                conn.commit()
                print(f"ğŸ“¦ SQLite ìºì‹œì—ì„œ {len(results)}ê°œ ì‚¬ì—…ì¥ ì •ë³´ ì¡°íšŒ")
                conn.close()
                return [dict(row) for row in results]
            
            conn.close()
            return []
    
    def set_workplace_cache(self, workplace_data: Dict, operation: str = 'insert'):
        """ì‚¬ì—…ì¥ ì •ë³´ë¥¼ ìºì‹œì— ì €ì¥/ì—…ë°ì´íŠ¸"""
        with self.lock:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (ì—…ë°ì´íŠ¸/ì‚­ì œ ì‹œ ë¹„êµìš©)
            cursor.execute("SELECT * FROM workplace_cache WHERE seq = ?", (workplace_data.get('seq'),))
            existing_data = cursor.fetchone()
            
            if operation == 'insert' or operation == 'update':
                cursor.execute("""
                    INSERT OR REPLACE INTO workplace_cache 
                    (seq, wkpl_nm, bzowr_rgst_no, data_crt_ym, wkpl_road_nm_dtl_addr,
                     jnngp_cnt, crrmm_ntc_amt, avg_monthly_salary, nw_acqzr_cnt, lss_jnngp_cnt,
                     updated_at, sync_status)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, 'pending')
                """, (
                    workplace_data.get('seq'),
                    workplace_data.get('wkplNm'),
                    workplace_data.get('bzowrRgstNo'),
                    workplace_data.get('dataCrtYm'),
                    workplace_data.get('wkplRoadNmDtlAddr'),
                    workplace_data.get('jnngpCnt'),
                    workplace_data.get('crrmmNtcAmt'),
                    workplace_data.get('avgMonthlySalary'),
                    workplace_data.get('nwAcqzrCnt'),
                    workplace_data.get('lssJnngpCnt')
                ))
                
                # ë™ê¸°í™” ë¡œê·¸ ê¸°ë¡
                self._log_sync_operation('workplace_cache', operation, workplace_data.get('seq'), 
                                       existing_data, workplace_data)
                
            elif operation == 'delete':
                cursor.execute("DELETE FROM workplace_cache WHERE seq = ?", (workplace_data.get('seq'),))
                
                # ë™ê¸°í™” ë¡œê·¸ ê¸°ë¡
                self._log_sync_operation('workplace_cache', operation, workplace_data.get('seq'), 
                                       existing_data, None)
            
            conn.commit()
            conn.close()
            print(f"ğŸ’¾ SQLite ìºì‹œì— ì‚¬ì—…ì¥ ë°ì´í„° {operation}: {workplace_data.get('wkplNm')}")
    
    def _log_sync_operation(self, table_name: str, operation: str, record_id: str, 
                          data_before: Any, data_after: Any):
        """ë™ê¸°í™” ì‘ì—… ë¡œê·¸ ê¸°ë¡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO sync_log 
            (table_name, operation, record_id, data_before, data_after, sync_status)
            VALUES (?, ?, ?, ?, ?, 'pending')
        """, (
            table_name,
            operation,
            record_id,
            json.dumps(data_before) if data_before else None,
            json.dumps(data_after) if data_after else None
        ))
        
        conn.commit()
        conn.close()
    
    def get_pending_sync_operations(self) -> List[Dict]:
        """ë™ê¸°í™” ëŒ€ê¸° ì¤‘ì¸ ì‘ì—…ë“¤ ì¡°íšŒ"""
        with self.lock:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT * FROM sync_log 
                WHERE sync_status = 'pending' 
                ORDER BY created_at ASC
            """)
            
            results = cursor.fetchall()
            conn.close()
            return [dict(row) for row in results]
    
    def mark_sync_completed(self, sync_id: int, success: bool = True, error_message: str = None):
        """ë™ê¸°í™” ì‘ì—… ì™„ë£Œ í‘œì‹œ"""
        with self.lock:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            if success:
                cursor.execute("""
                    UPDATE sync_log 
                    SET sync_status = 'synced', synced_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                """, (sync_id,))
                
                # workplace_cacheì˜ sync_statusë„ ì—…ë°ì´íŠ¸
                cursor.execute("""
                    SELECT record_id FROM sync_log WHERE id = ?
                """, (sync_id,))
                result = cursor.fetchone()
                if result:
                    cursor.execute("""
                        UPDATE workplace_cache 
                        SET sync_status = 'synced'
                        WHERE seq = ?
                    """, (result[0],))
            else:
                cursor.execute("""
                    UPDATE sync_log 
                    SET sync_status = 'error', error_message = ?
                    WHERE id = ?
                """, (error_message, sync_id))
            
            conn.commit()
            conn.close()
    
    def cleanup_expired_cache(self):
        """ë§Œë£Œëœ ìºì‹œ ë°ì´í„° ì •ë¦¬"""
        with self.lock:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ë§Œë£Œëœ API ìºì‹œ ì‚­ì œ
            cursor.execute("DELETE FROM api_cache WHERE expires_at < ?", (datetime.now(),))
            api_deleted = cursor.rowcount
            
            # ì˜¤ë˜ëœ ë™ê¸°í™” ë¡œê·¸ ì •ë¦¬ (30ì¼ ì´ìƒ)
            old_date = datetime.now() - timedelta(days=30)
            cursor.execute("DELETE FROM sync_log WHERE created_at < ? AND sync_status = 'synced'", (old_date,))
            log_deleted = cursor.rowcount
            
            conn.commit()
            conn.close()
            
            if api_deleted > 0 or log_deleted > 0:
                print(f"ğŸ§¹ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: API ìºì‹œ {api_deleted}ê°œ, ë¡œê·¸ {log_deleted}ê°œ ì‚­ì œ")
    
    def get_cache_stats(self) -> Dict:
        """ìºì‹œ í†µê³„ ì •ë³´ ì¡°íšŒ"""
        with self.lock:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # API ìºì‹œ í†µê³„
            cursor.execute("SELECT COUNT(*) FROM api_cache")
            api_cache_count = cursor.fetchone()[0]
            
            # ì‚¬ì—…ì¥ ìºì‹œ í†µê³„
            cursor.execute("SELECT COUNT(*) FROM workplace_cache")
            workplace_cache_count = cursor.fetchone()[0]
            
            # ë™ê¸°í™” ëŒ€ê¸° ì‘ì—… ìˆ˜
            cursor.execute("SELECT COUNT(*) FROM sync_log WHERE sync_status = 'pending'")
            pending_sync_count = cursor.fetchone()[0]
            
            # ê°€ì¥ ë§ì´ ì ‘ê·¼ëœ ì‚¬ì—…ì¥
            cursor.execute("""
                SELECT wkpl_nm, access_count FROM workplace_cache 
                ORDER BY access_count DESC LIMIT 5
            """)
            top_accessed = cursor.fetchall()
            
            conn.close()
            
            return {
                'api_cache_count': api_cache_count,
                'workplace_cache_count': workplace_cache_count,
                'pending_sync_count': pending_sync_count,
                'top_accessed_workplaces': top_accessed
            }
    
    def close(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë¦¬"""
        # SQLiteëŠ” íŒŒì¼ ê¸°ë°˜ì´ë¯€ë¡œ ë³„ë„ ì—°ê²° ì¢…ë£Œ ë¶ˆí•„ìš”
        print("ğŸ”Œ SQLite ìºì‹œ ì—°ê²° ì •ë¦¬ ì™„ë£Œ")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ìºì‹œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    cache = NPSCache()
    
    # í†µê³„ ì •ë³´ ì¶œë ¥
    stats = cache.get_cache_stats()
    print("ğŸ“Š ìºì‹œ í†µê³„:")
    print(f"  - API ìºì‹œ: {stats['api_cache_count']}ê°œ")
    print(f"  - ì‚¬ì—…ì¥ ìºì‹œ: {stats['workplace_cache_count']}ê°œ")
    print(f"  - ë™ê¸°í™” ëŒ€ê¸°: {stats['pending_sync_count']}ê°œ")
    
    cache.close()
